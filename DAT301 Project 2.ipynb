{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729e6078-3201-4f0f-8bb2-34d10136b00d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from sklearn import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95728302-a548-41a0-a2ae-49f6da2e0e9f",
   "metadata": {},
   "source": [
    "                                           Open Documents and save contents as string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7114cf77-e439-4f60-a0d2-7ab71cd38aba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EssayFileName = \"Vaccines are Beneficial.txt\"\n",
    "\n",
    "ResumeFileName = \"Resume.txt\"\n",
    "\n",
    "LabFileName = \"EEE 334 Lab 1.txt\"\n",
    "\n",
    "\n",
    "EssayLines = \"\"\n",
    "\n",
    "Resumelines = \"\"\n",
    "\n",
    "LabLines = \"\"\n",
    "\n",
    "\n",
    "def Read(FileName, lines):\n",
    "    with open(FileName, \"r\", encoding = 'utf-8') as File:\n",
    "        lines = File.read()\n",
    "    return(lines)\n",
    "    \n",
    "EssayText = Read(EssayFileName, EssayLines)\n",
    "\n",
    "ResumeText = Read(ResumeFileName, Resumelines)\n",
    "\n",
    "LabText = Read(LabFileName, LabLines)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05f609-89c2-4cbe-b962-b333c1ea70c2",
   "metadata": {},
   "source": [
    "                                                Clean  and Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2939f7ca-641f-4493-b2f9-bff892d0c9bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CleanData(Text):\n",
    "    Text = re.sub(r'[^a-zA-Z]', '', Text)\n",
    "    \n",
    "    Text = Text.lower()\n",
    "    \n",
    "    return(Text)\n",
    "\n",
    "EssayText = CleanData(EssayText)\n",
    "\n",
    "ResumeText = CleanData(ResumeText)\n",
    "\n",
    "LabText = CleanData(LabText) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf3c77-fc50-4fb9-8e7f-e367f0a22d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "I removed all non-alphabetic characters and changed all uppercase letters to lowercase.  That ensures I can obtain the frequency of just the letters and that all instances of the same letter will counted without regard to case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f2098-21c7-4878-bdd2-3e80b3b15c71",
   "metadata": {},
   "source": [
    "                                                 Get Letter Frequencies as Dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a49c563-c196-4e43-9f47-d16930dd98bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetFrequencies(Text):  \n",
    "    LetterFrequencies = {}\n",
    "    for keys in Text:\n",
    "        LetterFrequencies[keys] = LetterFrequencies.get(keys, 0) + 1\n",
    "    return(LetterFrequencies)\n",
    "\n",
    "EssayFrequencyDict = GetFrequencies(EssayText)\n",
    "\n",
    "ResumeFrequencyDict = GetFrequencies(ResumeText)\n",
    "\n",
    "LabFrequencyDict = GetFrequencies(LabText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2b1e2-4ee2-4355-a8fc-47170a8f3e80",
   "metadata": {
    "tags": []
   },
   "source": [
    "                                                Convert Dictionaries to Data Frames and Sort Frequency by Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfab4afb-96f5-4d8b-9cb8-dcffcb9964a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ConvertAndSort(FrequencyDict, column2):\n",
    "    Frequency_df = pd.DataFrame(FrequencyDict.items(), columns=['Letter', column2]) \n",
    "\n",
    "    Frequency_df = Frequency_df.sort_values(\"Letter\")\n",
    "\n",
    "    Frequency_df = Frequency_df[Frequency_df.Letter != \" \"].reset_index()  #renumber rows from 0 to 1 from the top down\n",
    "    \n",
    "    Frequency_df.pop('index')  #remove column containing prior order as I have no need of it\n",
    "    \n",
    "    Frequency_df.dropna(inplace = True) \n",
    "    \n",
    "    return(Frequency_df)\n",
    "    \n",
    "EssayFrequency_df = ConvertAndSort(EssayFrequencyDict, 'Essay Frequency')\n",
    "\n",
    "ResumeFrequency_df = ConvertAndSort(ResumeFrequencyDict, 'Resume Frequency')\n",
    "\n",
    "LabFrequency_df = ConvertAndSort(LabFrequencyDict, 'Lab Frequency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891f8f5-d7d9-414b-99c1-41a41548a09f",
   "metadata": {
    "tags": []
   },
   "source": [
    "                                                       Merge Dataframes and Get Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59ff89c9-2a27-4787-922c-e8e7551827b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\"Letter\" column in each df is the same, so two of them are being concantenated without it\n",
    "temp = pd.concat([EssayFrequency_df, ResumeFrequency_df.drop(['Letter'], axis = 1, inplace = False)], axis = 1, join = 'outer')\n",
    "\n",
    "merged_data = pd.concat([temp, LabFrequency_df.drop(['Letter'], axis = 1, inplace = False)], axis = 1, join = 'outer')\n",
    "\n",
    "merged_data.dropna(inplace = True)\n",
    "\n",
    "merged_data.columns = [\"Letter\", \"Essay\", \"Resume\", \"Lab\"]\n",
    "\n",
    "frequency_proportions = merged_data.copy()\n",
    "\n",
    "temp = frequency_proportions.iloc[:, 1:4]\n",
    "\n",
    "frequency_proportions.iloc[:, 1:4] = temp/sum(temp)\n",
    "\n",
    "frequency_proportions.columns = [\"Letter\", \"Essay\", \"Resume\", \"Lab\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33bcb60-97da-44a4-ac96-03a36cff8e2b",
   "metadata": {},
   "source": [
    "                                                         Get Summary Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42d6e3-6311-40e6-bfd2-aee355f7183f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since the data was sorted by letter in the previous step, each frequency category doesn't need its own separate letter category, hence, I dropped that column from the resume and lab df's, keeping it on the essay df, and then concantenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a110a5b0-0df2-4637-be66-dad0d2776c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Letter Counts</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Letter Proportions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Essay</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Lab</th>\n",
       "      <th>Essay</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>530.85</td>\n",
       "      <td>110.31</td>\n",
       "      <td>479.58</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>477.23</td>\n",
       "      <td>95.49</td>\n",
       "      <td>392.42</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>189.00</td>\n",
       "      <td>27.25</td>\n",
       "      <td>197.00</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>332.00</td>\n",
       "      <td>93.00</td>\n",
       "      <td>375.00</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>185.00</td>\n",
       "      <td>810.75</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1901.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>1471.00</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Letter Counts                   Letter Proportions              \n",
       "             Essay  Resume      Lab               Essay Resume    Lab\n",
       "mean        530.85  110.31   479.58               0.038  0.038  0.038\n",
       "std         477.23   95.49   392.42               0.035  0.033  0.031\n",
       "min           7.00    5.00    14.00               0.001  0.002  0.001\n",
       "25%         189.00   27.25   197.00               0.014  0.010  0.016\n",
       "50%         332.00   93.00   375.00               0.024  0.032  0.030\n",
       "75%         864.25  185.00   810.75               0.063  0.065  0.065\n",
       "max        1901.00  300.00  1471.00               0.138  0.105  0.118"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryStats = (merged_data.describe()).round(decimals = 2)\n",
    "\n",
    "SummaryStats_Proportions = (frequency_proportions.describe()).round(decimals = 3)\n",
    "\n",
    "summary_stats = pd.concat([SummaryStats, SummaryStats_Proportions], axis = 1, join = 'outer', \n",
    "                           keys = ['Letter Counts', ' Letter Proportions'])\n",
    "\n",
    "summary_stats.drop('count', inplace = True)\n",
    "\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf512525-6d0c-4f3b-a438-6d3eaba376eb",
   "metadata": {},
   "source": [
    "                                                        Summary Stats by Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83fdf1-2829-4c4c-9736-e90fa3e65ca6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#easiest way to get stats for data grouped by letter is to make the letters index names and transpose the df.  \n",
    "#When I used the groupby function instead, .describe gave weird results.\n",
    "\n",
    "make_letters_index = merged_data.copy() \n",
    "#I don't want to make the letters variables on the original df though because still I want \n",
    "#to be able to use 'Letter' as a grouping variable for graphing.  Hence, the use of the copy function \n",
    "#so that changes to make_letters_index aren't seen by merged_data\n",
    "\n",
    "make_letters_index.index = ['a', 'b', 'c', 'd', 'e', 'f', 'g', \n",
    "                     'h', 'i', 'j', 'k', 'l', 'm', 'n', \n",
    "                     'o', 'p', 'q', 'r', 's', 't', 'u', \n",
    "                     'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "#Remove 'Letter' column, as the index values now hokd that information\n",
    "GroupByLetter = make_letters_index.drop('Letter', axis = 1)\n",
    "\n",
    "GroupByLetter = GroupByLetter.transpose()\n",
    "\n",
    "\n",
    "SummaryStatsByLetter = (GroupByLetter.describe()).round(decimals = 2)\n",
    "\n",
    "SummaryStatsByLetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914de654-344e-4b78-a4c3-6db169be1ca2",
   "metadata": {},
   "source": [
    "                                                            Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fd7de-c374-4e3e-b8d4-573cdea8be0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.box(merged_data).show()\n",
    "\n",
    "px.box(GroupByLetter).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f148dd-7bf3-4ee8-a0b5-8a49746d7dce",
   "metadata": {
    "tags": []
   },
   "source": [
    "                                                             Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00232b82-1911-4a94-a6a1-e569947ee3b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def BarGraph(df, Title, Color, Y):\n",
    "    bar_graph = go.Figure(data = [go.Bar(x = df[\"Letter\"], y = df[Y])])\n",
    "    bar_graph.update_traces(marker_color = Color)\n",
    "    bar_graph.update_layout(title_text = Title)\n",
    "    bar_graph.show()\n",
    "\n",
    "BarGraph(EssayFrequency_df, \"Frequencies of Letters in Essay\", \"darkviolet\", 'Essay Frequency')\n",
    "\n",
    "BarGraph(ResumeFrequency_df, \"Frequencies of Letters in Resume\", \"deeppink\", 'Resume Frequency')\n",
    "\n",
    "BarGraph(LabFrequency_df, \"Frequencies of Letters in Lab Report\", \"deepskyblue\", 'Lab Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9447c0-f69a-4703-b5b1-6fcffc6a98b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_palette(\"hls\", 26)\n",
    "\n",
    "def histogram(df, Title, X):\n",
    "    hist = sns.displot(df, x = X, bins = 15, hue = 'Letter', multiple = 'stack', stat = 'probability')\n",
    "    hist.fig.suptitle(Title)\n",
    "    \n",
    "histogram(EssayFrequency_df, \"Frequencies of Letters in Essay\", 'Essay Frequency')\n",
    "histogram(ResumeFrequency_df, \"Frequencies of Letters in Resume\", 'Resume Frequency')\n",
    "histogram(LabFrequency_df, \"Frequencies of Letters in Lab Report\", 'Lab Frequency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce640da-ecf4-4d0f-9d06-f43e05d94f8d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def CreateWordCloud(text):\n",
    "    #Primary Source for writing this function: https://www.geeksforgeeks.org/generating-word-cloud-python/ \n",
    "    \n",
    "    stopwords = set(STOPWORDS)\n",
    "\n",
    "    # create wordcloud object\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words = 200, stopwords = stopwords)\n",
    "    wordcloud.generate(text)\n",
    "\n",
    "    plt.figure(figsize = (10, 10), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "CreateWordCloud(EssayText)\n",
    "CreateWordCloud(ResumeText)\n",
    "CreateWordCloud(LabText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862df30-702f-4dd4-82d8-d2d2cfe408a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52d507-c0e8-4f9f-978b-c37d61c85d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
